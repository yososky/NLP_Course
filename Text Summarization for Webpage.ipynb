{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIT 590\n",
    "# Mingtao Zhang\n",
    "# Lab_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4 as bs  # BeautifulSoup\n",
    "import urllib.request\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Web scraping\n",
    "1 (0.5 points) Use the web scraping technique with BeautifulSoup as shown in class to get the\n",
    "text data from the specified data location on the Wikipedia webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _scrape_webpage_fixed(url):\n",
    "    \"\"\"\n",
    "    Use BeautifulSoup to scrape the webpage text contents.\n",
    "    \"\"\"    \n",
    "    scraped_textdata = urllib.request.urlopen(url)\n",
    "    textdata = scraped_textdata.read()\n",
    "    parsed_textdata = bs.BeautifulSoup(textdata,'lxml')\n",
    "    #paragraphs = parsed_textdata.find_all(['p', 'dd','li'])  #dd and li includes some informations, but some unrealted\n",
    "    paragraphs = parsed_textdata.find_all(['p'])\n",
    "    formated_text = \"\"\n",
    "    \n",
    "    for para in paragraphs:\n",
    "        line = para.text.lower() # change to lower case\n",
    "        line = re.sub(r\"[^a-z\\s]\", \"\", line.strip())  # only contains english words\n",
    "        formated_text += line\n",
    "    \n",
    "    return formated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'natural language processing nlp is a subfield of linguistics computer science and artificial intelligence concerned with the interactions between computers and human language in particular how to program computers to process and analyze large amounts of natural language datachallenges in natural language processing frequently involve speech recognition natural language understanding and naturallanguage generationnatural language processing has its roots in the s already in  alan turing published an article titled computing machinery and intelligence which proposed what is now called the turing test as a criterion of intelligence a task that involves the automated interpretation and generation of natural language but at the time not articulated as a problem separate from artificial intelligencethe premise of symbolic nlp is wellsummarized by john searles chinese room experiment given a collection of rules eg a chinese phrasebook with questions and matching answers the computer emulates '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = _scrape_webpage_fixed('https://en.wikipedia.org/wiki/Natural_language_processing')\n",
    "#text\n",
    "text[0:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edit text\n",
    "## 2 (3.5 points) Process the text data and must include:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Tokenize the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk  # import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1235\n",
      "['natural', 'language', 'processing', 'nlp', 'is', 'a', 'subfield', 'of', 'linguistics', 'computer', 'science', 'and', 'artificial', 'intelligence', 'concerned', 'with', 'the', 'interactions', 'between', 'computers', 'and', 'human', 'language', 'in', 'particular', 'how', 'to', 'program', 'computers', 'to']\n"
     ]
    }
   ],
   "source": [
    "tokenizedText = nltk.word_tokenize(text)\n",
    "print(len(tokenizedText))\n",
    "print(tokenizedText[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 (1 point) Remove the stop words, punctuation, and digit numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove numbers and punctuation\n",
    "This process has been done in web scraping part,\n",
    "/*line = re.sub(r\"[^a-z\\s]\", \"\", line.strip())  # only contains english words */\n",
    "\n",
    "only english words are record in the text\n",
    "\n",
    "But the function below has the same function which i used in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from string import punctuation\n",
    "#from nltk.corpus import stopwords\n",
    "#stopword = stopwords.words('english')\n",
    "\n",
    "def cleanUpSentense(token_sent):\n",
    "    senttoken = nltk.word_tokenize(token_sent)\n",
    "    leSent = lemmatizeWords(senttoken)  # lemmatize senstnce\n",
    "    noStopwords = [word for word in leSent if word not in stopword]  # remove stop words\n",
    "    formated_text = \"\"\n",
    "    for para in noStopwords:\n",
    "        line = para.lower() # change to lower case\n",
    "        line = line.replace('\\n','')\n",
    "        outNumline = ''.join(c for c in line if not c.isdigit())  # take off number\n",
    "        outPunc = ''.join(c for c in outNumline if c not in punctuation) # take off puncctutation\n",
    "        formated_text += outPunc + \" \"\n",
    "    return formated_text\n",
    "\n",
    "#print(cleanUpSentense(token_sent[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "741\n",
      "['natural', 'language', 'processing', 'nlp', 'subfield', 'linguistics', 'computer', 'science', 'artificial', 'intelligence', 'concerned', 'interactions', 'computers', 'human', 'language', 'particular', 'program', 'computers', 'process', 'analyze', 'large', 'amounts', 'natural', 'language', 'datachallenges', 'natural', 'language', 'processing', 'frequently', 'involve']\n"
     ]
    }
   ],
   "source": [
    "def _removeStopWords(tokenedWords):\n",
    "    stopword = stopwords.words('english')\n",
    "    removing_stopwords = [word for word in tokenedWords if word not in stopword]\n",
    "    return removing_stopwords\n",
    "cleanedTokenWords = _removeStopWords(tokenizedText)\n",
    "print(len(cleanedTokenWords))\n",
    "print(cleanedTokenWords[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 (1.5 points) write a function to lemmatize the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "741\n",
      "['natural', 'language', 'processing', 'nlp', 'subfield', 'linguistics', 'computer', 'science', 'artificial', 'intelligence', 'concerned', 'interaction', 'computer', 'human', 'language', 'particular', 'program', 'computer', 'process', 'analyze', 'large', 'amount', 'natural', 'language', 'datachallenges', 'natural', 'language', 'processing', 'frequently', 'involve']\n"
     ]
    }
   ],
   "source": [
    "def lemmatizeWords(tokenText):\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_word = [wordnet_lemmatizer.lemmatize(word) for word in tokenText]\n",
    "    return lemmatized_word\n",
    "\n",
    "lemmatizedText = lemmatizeWords(cleanedTokenWords)\n",
    "print(len(lemmatizedText))\n",
    "print(lemmatizedText[:30])\n",
    "# line 2, computers -> computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 (0.4 points) Calculate the word distribution using FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'language': 24, 'natural': 16, 'processing': 13, 'nlp': 11, 'task': 11, 'statistical': 11, 'machine': 9, 'algorithm': 9, 'rule': 8, 'learning': 8, ...})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# freq dist find the frequency of each words order DESC\n",
    "freqdic = nltk.FreqDist(lemmatizedText)\n",
    "freqdic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 (0.3 points) List and plot the top 15 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('language', 24),\n",
       " ('natural', 16),\n",
       " ('processing', 13),\n",
       " ('nlp', 11),\n",
       " ('task', 11),\n",
       " ('statistical', 11),\n",
       " ('machine', 9),\n",
       " ('algorithm', 9),\n",
       " ('rule', 8),\n",
       " ('learning', 8),\n",
       " ('model', 8),\n",
       " ('cognitive', 8),\n",
       " ('system', 7),\n",
       " ('word', 7),\n",
       " ('linguistics', 6)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqdic.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fb7725652d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqdic.plot(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summerize\n",
    "## 3 (4.5 points) Summarize the text as shown in class:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 (1.5 points) Calculate word Weighted frequency\n",
    "Please specify the math formula.\n",
    "Hint: it would be easy to use FreqDist to get original word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'natural language processing (nlp) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data.challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural-language generation.natural language processing has its roots in the 1950s. already in 1950, alan turing published an article titled \"computing machinery and intelligence\" which proposed what is now called the turing test as a criterion of intelligence, a task that involves the automated interpretation and generation of natural language, but at the time not articulated as a problem separate from artificial intelligence.the premise of symbolic nlp is well-summarized by john searle\\'s chinese room experiment: given a collection of rules (e.g., a chinese phrasebook, with questions and matchi'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# download the page again\n",
    "def _scrape_webpage_with(url):\n",
    "    \"\"\"\n",
    "    Use BeautifulSoup to scrape the webpage text contents.\n",
    "    \"\"\"    \n",
    "    scraped_textdata = urllib.request.urlopen(url)\n",
    "    textdata = scraped_textdata.read()\n",
    "    parsed_textdata = bs.BeautifulSoup(textdata,'lxml')\n",
    "    paragraphs = parsed_textdata.find_all(['p'])\n",
    "    formated_text = \"\"\n",
    "    \n",
    "    for para in paragraphs:\n",
    "        line = para.text.lower() # change to lower case\n",
    "        line = line.replace('\\n','')\n",
    "        formated_text += line\n",
    "    \n",
    "    return formated_text\n",
    "\n",
    "textFull = _scrape_webpage_with('https://en.wikipedia.org/wiki/Natural_language_processing')\n",
    "textFull[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'natural language processing (nlp) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data.challenges in natural language processing frequently involve speech recognition, natural language understanding, and natural-language generation.natural language processing has its roots in the 1950s.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the token as sentense \n",
    "from nltk.tokenize import sent_tokenize\n",
    "token_sent = sent_tokenize(textFull)\n",
    "token_sent[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "stopword = stopwords.words('english')\n",
    "\n",
    "def cleanUpSentense(token_sent):\n",
    "    senttoken = nltk.word_tokenize(token_sent)\n",
    "    leSent = lemmatizeWords(senttoken)  # lemmatize senstnce\n",
    "    noStopwords = [word for word in leSent if word not in stopword]  # remove stop words\n",
    "    formated_text = \"\"\n",
    "    for para in noStopwords:\n",
    "        line = para.lower() # change to lower case\n",
    "        #line = line.replace('\\n','')\n",
    "        outNumline = ''.join(c for c in line if not c.isdigit())  # take off number\n",
    "        outPunc = ''.join(c for c in outNumline if c not in punctuation) # take off puncctutation\n",
    "        if len(outPunc) > 1:\n",
    "            formated_text += outPunc + \" \"\n",
    "    return formated_text\n",
    "#print(cleanUpSentense(token_sent[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'natural language processing nlp subfield linguistics computer science artificial intelligence concerned interaction computer human language particular program computer process analyze large amount natural language datachallenges natural language processing frequently involve speech recognition natural language understanding naturallanguage generationnatural language processing ha root '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clean up all the sentances in the tokenset\n",
    "for idx in range(0,len(token_sent)):\n",
    "    token_sent[idx] = cleanUpSentense(token_sent[idx])\n",
    "token_sent[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate the weight of each words\n",
    "\n",
    "refernce: https://www.tutorialspoint.com/gensim/gensim_creating_tf_idf_matrix.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The function we use is TF-IDF\n",
    "\n",
    "weight = tf * log(N/df+1)\n",
    "\n",
    "TF -> probability of finding a word in the docutment  ->  appearTimes / total_words or appearTimes, here I use appearTimes\n",
    "\n",
    "IDF -> log(total sentances / sentance with this word + 1) -> +1 for regard case in 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pprint\n",
    "from gensim import corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import TfidfModel\n",
    "\n",
    "doc_tokenized = [simple_preprocess(doc) for doc in token_sent]\n",
    "dictionary = corpora.Dictionary()\n",
    "BoW_corpus = [dictionary.doc2bow(doc, allow_update=True) for doc in doc_tokenized]\n",
    "#for doc in BoW_corpus: print([[dictionary[id], freq] for id, freq in doc])\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "tfidf = TfidfModel(BoW_corpus, smartirs='ntc')\n",
    "#for doc in tfidf[BoW_corpus]: print([[dictionary[id], np.around(freq,decimals=6)] for id, freq in doc])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 (1.5 points) Score the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'amount': 0.1919,\n",
       " 'analyze': 0.1919,\n",
       " 'artificial': 0.10584,\n",
       " 'computer': 0.14335,\n",
       " 'concerned': 0.1919,\n",
       " 'datachallenges': 0.1919,\n",
       " 'frequently': 0.1919,\n",
       " 'ha': 0.12879,\n",
       " 'human': 0.16859,\n",
       " 'intelligence': 0.21167}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordScore = {}\n",
    "for doc in tfidf[BoW_corpus]:\n",
    "    for id, req in doc:\n",
    "        wordScore[dictionary[id]] = np.around(req,decimals=5)\n",
    "\n",
    "dict(list(wordScore.items())[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'starting late however wa revolution natural language processing introduction machine learning algorithm language processing ': 2.0461600000000004,\n",
       " 'wa due steady increase computational power see moore law gradual lessening dominance chomskyan theory linguistics eg ': 3.6817300000000013,\n",
       " 'transformational grammar whose theoretical underpinnings discouraged sort corpus linguistics underlies machinelearning approach language processing ': 2.90235}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentScore = {}\n",
    "for sent in token_sent:\n",
    "    for word in nltk.word_tokenize(sent):\n",
    "        if word in wordScore.keys():\n",
    "            if len(sent.split(' ')) < 30:\n",
    "                if sent not in sentScore.keys():\n",
    "                    sentScore[sent] = wordScore[word]\n",
    "                else:\n",
    "                    sentScore[sent] += wordScore[word]\n",
    "                    \n",
    "dict(list(sentScore.items())[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Since the score didn't went well, I choose to use other method instead of gensim\n",
    "\n",
    "reference: https://stackabuse.com/text-summarization-with-nltk-in-python/#:~:text=Text%20summarization%20is%20a%20subdomain,and%20deep%20learning%2Dbased%20techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'natural': 0.6666666666666666,\n",
       " 'language': 1.0,\n",
       " 'processing': 0.5833333333333334,\n",
       " 'nlp': 0.4583333333333333,\n",
       " 'subfield': 0.041666666666666664}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents = \"\"\n",
    "token_sent = sent_tokenize(textFull)\n",
    "for idx in range(0,len(token_sent)):\n",
    "    token_sent[idx] = cleanUpSentense(token_sent[idx])\n",
    "for sent in token_sent:\n",
    "    sents += sent\n",
    "sents = nltk.word_tokenize(sents)\n",
    "\n",
    "\n",
    "#BoW\n",
    "freqDict = nltk.FreqDist(sents)\n",
    "max_freq = max(freqDict.values())\n",
    "wordFreq = {}\n",
    "\n",
    "for key in freqDict.keys():\n",
    "    wordFreq[key] = (freqDict[key]/max_freq)\n",
    "\n",
    "    \n",
    "dict(list(wordFreq.items())[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'natural': 0.021361815754339118,\n",
       " 'language': 0.03204272363150868,\n",
       " 'processing': 0.018691588785046728,\n",
       " 'nlp': 0.014686248331108143,\n",
       " 'subfield': 0.0013351134846461949}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find TF\n",
    "wordCnt = dict.fromkeys(sents, 0)\n",
    "totalCnt = len(sents);\n",
    "for word in sents:\n",
    "    wordCnt[word] += 1\n",
    "\n",
    "    \n",
    "tfDict = {}\n",
    "for word, cnt in wordCnt.items():\n",
    "    tfDict[word] = cnt / totalCnt\n",
    "\n",
    "dict(list(tfDict.items())[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'natural': 5.925591802957274,\n",
       " 'language': 5.925591802957274,\n",
       " 'processing': 5.925591802957274,\n",
       " 'nlp': 5.925591802957274,\n",
       " 'subfield': 5.925591802957274}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find IDF\n",
    "import math\n",
    "\n",
    "idfDict = dict.fromkeys(sents, 0)\n",
    "for word, cnt in wordCnt.items():\n",
    "    if cnt > 0:\n",
    "        idfDict[word] += 1\n",
    "for word, cnt in idfDict.items():\n",
    "    idfDict[word] = math.log(totalCnt / (cnt + 1))\n",
    "\n",
    "dict(list(idfDict.items())[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'natural': 0.12658140033019544,\n",
       " 'language': 0.18987210049529316,\n",
       " 'processing': 0.110758725288921,\n",
       " 'nlp': 0.08702471272700936,\n",
       " 'subfield': 0.007911337520637215}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get tfidf\n",
    "tfidf = {}\n",
    "for word, cnt in tfDict.items():\n",
    "    tfidf[word] = cnt * idfDict[word]\n",
    "\n",
    "dict(list(tfidf.items())[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score of sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing.': 0.957271839997103,\n",
       " \"this was due to both the steady increase in computational power (see moore's law) and the gradual lessening of the dominance of chomskyan theories of linguistics (e.g.\": 0.18987210049529318,\n",
       " 'transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.': 0.5063256013207817}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentenceScore = {}\n",
    "token_sent = sent_tokenize(textFull)\n",
    "\n",
    "for sent in token_sent:\n",
    "    for word in nltk.word_tokenize(sent):\n",
    "        if word in tfidf.keys():\n",
    "            if len(sent.split(' ')) < 30:\n",
    "                if sent not in sentenceScore.keys():\n",
    "                    sentenceScore[sent] = tfidf[word]\n",
    "                else:\n",
    "                    sentenceScore[sent] += tfidf[word]\n",
    "\n",
    "dict(list(sentenceScore.items())[0:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 (1.5 points) Build a summary (based on ratio, sentence or word count, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting in the late 1980s, however, there was a revolution in natural language processing with the introduction of machine learning algorithms for language processing. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing. increasingly, however, research has focused on statistical models, which make soft, probabilistic decisions based on attaching real-valued weights to each input feature. the cache language models upon which many speech recognition systems now rely are examples of such statistical models. when used as a stative verb, as in ”tomorrow is a big day”, a likely inference of the author’s intent it that ”big” is being used to imply ”importance”. since the early 2010s,[16] the field has thus largely abandoned statistical methods and shifted to neural networks for machine learning. [26] cognitive linguistics is an interdisciplinary branch of linguistics, combining knowledge and research from both psychology and linguistics.\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "summary_sentences = heapq.nlargest(7, sentenceScore, key=sentenceScore.get)\n",
    "summary = ' '.join(summary_sentences)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 (0.5 point) Summarize the same text data using Gensim with TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'already in 1950, alan turing published an article titled \"computing machinery and intelligence\" which proposed what is now called the turing test as a criterion of intelligence, a task that involves the automated interpretation and generation of natural language, but at the time not articulated as a problem separate from artificial intelligence.the premise of symbolic nlp is well-summarized by john searle\\'s chinese room experiment: given a collection of rules (e.g., a chinese phrasebook, with questions and matching answers), the computer emulates natural language understanding (or other nlp tasks) by applying those rules to the data it is confronted with.up to the 1980s, most natural language processing systems were based on complex sets of hand-written rules.\\nthis was due to both the steady increase in computational power (see moore\\'s law) and the gradual lessening of the dominance of chomskyan theories of linguistics (e.g. transformational grammar), whose theoretical underpinnings discouraged the sort of corpus linguistics that underlies the machine-learning approach to language processing.[6]in the 2010s, representation learning and deep neural network-style machine learning methods became widespread in natural language processing, due in part to a flurry of results showing that such techniques[7][8] can achieve state-of-the-art results in many natural language tasks, for example in language modeling,[9] parsing,[10][11] and many others.in the early days, many language-processing systems were designed by symbolic methods, i.e., the hand-coding of a set of rules, coupled with a dictionary lookup:[12][13] such as by writing grammars or devising heuristic rules for stemming.more recent systems based on machine-learning algorithms have many advantages over hand-produced rules: despite the popularity of machine learning in nlp research, symbolic methods are still (2020) commonly usedsince the so-called \"statistical revolution\"[14][15] in the late 1980s and mid-1990s, much natural language processing research has relied heavily on machine learning.\\nthe machine-learning paradigm calls instead for using statistical inference to automatically learn such rules through the analysis of large corpora (the plural form of corpus, is a set of documents, possibly with human or computer annotations) of typical real-world examples.many different classes of machine-learning algorithms have been applied to natural-language-processing tasks.\\nhowever, part-of-speech tagging introduced the use of hidden markov models to natural language processing, and increasingly, research has focused on statistical models, which make soft, probabilistic decisions based on attaching real-valued weights to the features making up the input data.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.summarization import summarize\n",
    "summarize(textFull)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 (1 point) Compare 3.1 method with Gensim-TextRank. What’s different and why? Could your methods be improved? And How to improve? Please clearly explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference: \n",
    "Summarized with gensim will contains a lot of useless numbers and punctuations. This is avoid by clean up during our section. But their summarized includes more information than use since they are having a bigger and better score system. Its IDF score has a larger base than mine. This makes its acuracy become highter than mine.\n",
    "\n",
    "Although I can acurately calculate the TF score for my document. The biggest problem for my project is lack of paragraphs and inaccurate word scores. In order to improve it, i will use outsoucre, like some APIs to calcualte the IDF score for me. A larger system will give back a better score.\n",
    "\n",
    "Another way I can imporve it is to use webScraping method to download multiple related pages to increase my IDF score.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
